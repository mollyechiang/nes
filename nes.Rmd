---
title: "NES"
author: "Molly Chiang"
date: "3/3/2020"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(rstanarm)
library(report)
library(tidyverse)

load("nes.rda")
```

```{r clean_data}
# This data is a mess. Where is the code book? Is this real NES data or some bs
# made up sample? This is a really good place to write down some thoughts on
# this data and where it comes from. Take a look at ROAS, pages 141 -- 142.

# We are trying to explain partyid7, which is the party identification of each
# respondent. Can we treat this as continuous? I think that lower numbers mean
# more Democratic.

# real_ideo is missing a lot. Should we just get rid of those rows? Depends on
# the time period we care about . . .

x <- nes %>% 
  as_tibble() %>% 
  select(year, partyid7, real_ideo, race_adj, 
         age_discrete, educ1, female, income) %>% 
  drop_na() %>% 
  mutate(gender = as.factor(ifelse(female == 1, "female", "non-female"))) %>% 
  mutate(race = as.factor(case_when(race_adj == 1 ~ "White",
                                    race_adj == 2 ~ "Black",
                                    TRUE ~ "Other")))
  
```

```{r model_1, cache=TRUE}
# What is the relationship, if any, between partyid7 and female? We will treat
# partyid7 as a continuous variable for this exercise, even though it is a
# categorical variable with 7 levels. Recall that 1 means Strong Democrat, 2
# means Democrat and so on, finishing with 7 for Strong Republican.

fit_1 <- stan_glm(data = x, partyid7 ~ gender, refresh = 0)
```

```{r model_2, cache=TRUE}
# What about the relationship between race and party ID? Need to have created a
# factor variable, or at least a character variable.

fit_2 <- stan_glm(data = x, partyid7 ~ race, refresh = 0)
```


```{r model_3, cache=TRUE}
fit_3 <- stan_glm(data = x, partyid7 ~ real_ideo, refresh = 0)
```

## Model Results

Here is a nicely printed summary of my model results, showing the relationship between party ID, on a 1 through 7 scale, and ideology, also on a 1 through 7 scale. Although these are ordered categories, I treat both variables as continuous.

```{r show_the_model, comment=NA}
print(fit_3, detail = FALSE, digits = 2)
```

It isn't the best thing I could imagine. I really want to figure out a way to add a caption. But it will do for now. 

Instead of just printing the simple object, we could print its summary.


```{r show_the_model_summary, comment=NA}
print(summary(fit_3), detail = FALSE, digits = 2)
```

But that adds a bunch of junk, including run-off-the-page text. Maybe there are options in something like `print.stanmvreg()` which might be helpful. Has no one bothered to ask on RStudio Community?

```{r left_over, include=FALSE}

# partyid is what we are trying to explain

pred <- x %>% 
  select(partyid7, gender, race, real_ideo) %>% 
  mutate(pred_gender = predict(fit_1, x)) %>% 
  mutate(pred_race = predict(fit_2, x)) %>% 
  mutate(pred_idea = predict(fit_3, x)) %>% 
  # slice(8000:8010) %>%
  # Interesting rows.
  mutate(id = rep(1:nrow(x)))

# How similar/different are these predictions?

# How do we know if a prediction is good?

# How much do bad predictions differ?

# Think about penalty functions and decision-making.


```

```{r graphic realting pred_gender and gender}

ggplot(pred, aes(x = pred_gender, y = partyid7, color = gender)) +
  geom_jitter(width = .03, height = .3, alpha = .07)

ggplot(pred, aes(x = pred_gender, y = partyid7, group = pred_gender, color = gender)) +
  geom_boxplot()

ggplot(pred, aes(x = id)) +
  geom_point(aes(y = pred_gender, color = "BLUE")) +
  geom_point(aes(y = partyid7, color = "RED")) +
  labs(x = "Person",
       y = "Party ID Value",
       colour = "Value") +
  scale_color_discrete(labels = c("Prediction", "Actual"))

```

```{r model with many preditors}

big_fit <- stan_glm(data = x, partyid7 ~ gender + race + real_ideo, refresh = 0)

print(big_fit)

# the intercept tells us the predicted partyid7 value for a black female voter 
# with a real_ideo of 0 (when everything is 0)

# changing the scale of real_ideo from 1-7 to 0-6 will just shift the line,
# not change any of the slopes
# in addition, the intercept will have a real-world interpretation

# THINGS TO THINK ABOUT WHEN MAKING A MODEL (pg 145)
# 1. Validity - data you are analyzing matches the question you are asking - remember that any model is really never a perfect representation of the world - but can always answer questions according to specific assumptions 
# 2. Representativeness - how representative is our sample of the general population - more about where the data was collected from - did we miss demographics in collecting our data?
# 3. Additivty and Linearity

```

Posterior Predictive Checks
- fake data simulation - assume your model is correct, and create new data based on that model 
    - and usually introduce some uncertainty



```{r}
# Fit a model similar to that in Gelman for the whole period. Interpret the
# details of the model. And, yes, you will be seeing questions similar to this
# on the exam!

# Now fit the model for a single year. The coefficient values are different!
# Which ones are true?

# Let's do as ROAS does and fit the model for each year. Recall all your
# list-column tricks from Gov 1005.

# Once we have that collection of models. Can we make a plot which looks like at
# least one of the panes from page 142?


```

